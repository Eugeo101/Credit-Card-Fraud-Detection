# Credit Card Fraud Detection üõ°Ô∏èüí≥  

This project aims to detect fraudulent credit card transactions using machine learning techniques while addressing the challenges of imbalanced data.  

## üìù Problem Statement  
Fraudulent transactions constitute a small fraction of total credit card transactions, making it a highly imbalanced classification problem. The goal is to accurately identify fraud while minimizing false positives and negatives.  

## üîç Steps Followed  

### Data:
Credit Card Frauds Data:
https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

### 1Ô∏è‚É£ Understanding the Data  
- Explored columns and data types.  
- Described numerical and categorical features.  

### 2Ô∏è‚É£ Exploratory Data Analysis (EDA)  
- **Univariate Analysis:** Used histograms, distribution plots, and count plots to analyze feature distributions.  
- **Bivariate Analysis:** Investigated relationships between numerical and categorical variables using scatter, box, and violin plots.  
- **Multivariate Analysis:** Employed pair plots and correlation heatmaps for deeper insights.  

### 3Ô∏è‚É£ Pre-Processing  
- Handled duplicates and missing values.  
- Applied feature encoding for categorical variables (OneHotEncoder, BinaryEncoder, etc.).  
- Addressed imbalanced data using SMOTE and undersampling.  
- Scaled features using StandardScaler, MinMaxScaler, and RobustScaler.  

### 4Ô∏è‚É£ Modeling  
- Compared models with and without balancing techniques.  
- Optimized hyperparameters using GridSearchCV and RandomizedSearchCV.  
- Evaluated model performance using accuracy, recall, and precision.  

### ‚úÖ Results  
- Achieved **99.9% test accuracy** with the best-performing Logistic Regression model.  
- Recall: **87%**, Precision: **65%** (focused on minimizing false negatives).  

### 5Ô∏è‚É£ Model Deployment  
- Saved the trained model for future use.  

## üìÇ Repository Contents  
- **Dataset**: Pre-processed and cleaned data.  
- **Notebooks**: Detailed steps for EDA, pre-processing, and modeling.  
- **Results**: Performance metrics and comparisons.  
- **Saved Model**: Final Logistic Regression model.  

## üìä Key Insights  
- Oversampling (SMOTE) significantly improved model performance.  
- Logistic Regression proved effective for this classification problem.  

---
